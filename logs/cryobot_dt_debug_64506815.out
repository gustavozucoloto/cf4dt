HOME_REAL:      /rwthfs/rz/cluster/home/kq336027
MAMBA_ROOT:     /rwthfs/rz/cluster/home/kq336027/.micromamba
Job started on: n23m0173.hpc.itc.rwth-aachen.de
Project dir:    /rwthfs/rz/cluster/home/kq336027/cf4dt
CPUs per task:  16
MAMBA_ROOT:     /rwthfs/rz/cluster/home/kq336027/.micromamba

=== Sanity check: Python + MPI vendor ===
Python OK
MPI vendor: ('MPICH', (4, 3, 2))
MPI library: MPICH Version:      4.3.2
COMM_WORLD size: 1

=== Step 1: Generating artificial data -> data/artificial_Qlc_data.csv ===
Note: Edit velocity/temperature lists and n_jobs in scripts/generate_artificial_data.py
Running 20 simulations serially...
  Progress: 10/20
  Progress: 20/20

Saved dataset with 20 points to: data/artificial_Qlc_data.csv
Qlc_true_kW: min/median/max = 1.8778042398325266e-07 2.5825593119642707e-06 1.0736964641673413e-05

============================================================
MODEL: powerlaw
============================================================
=== Step 2: Training GP emulator -> data/gp_powerlaw.joblib ===
[powerlaw] Pre-compiling FEniCS forms to avoid race conditions...
[powerlaw] Building training set with 16 parallel processes...
  [powerlaw] Progress: 50/400
  [powerlaw] Progress: 100/400
  [powerlaw] Progress: 150/400
  [powerlaw] Progress: 200/400
  [powerlaw] Progress: 250/400
  [powerlaw] Progress: 300/400
  [powerlaw] Progress: 400/400
  [powerlaw] Progress: 350/400
Saved GP emulator: data/gp_powerlaw.joblib
Kernel: 10**2 * Matern(length_scale=[3.74, 9.46, 15.3, 53.9], nu=2.5) + WhiteKernel(noise_level=1e-08)

=== Step 3: Bayesian calibration (emcee) -> data/posterior_powerlaw.npy ===
Saved posterior samples to data/posterior_powerlaw.npy
powerlaw posterior mean: [-15.82691171   1.01042354] std: [0.1324301  0.37893588]

=== Step 4: UQ plots -> outputs/uq_powerlaw* ===

============================================================
MODEL: exponential
============================================================
=== Step 2: Training GP emulator -> data/gp_exponential.joblib ===
[exponential] Pre-compiling FEniCS forms to avoid race conditions...
[exponential] Building training set with 16 parallel processes...
  [exponential] Progress: 50/400
  [exponential] Progress: 100/400
  [exponential] Progress: 150/400
  [exponential] Progress: 200/400
  [exponential] Progress: 250/400
  [exponential] Progress: 300/400
  [exponential] Progress: 400/400
  [exponential] Progress: 350/400
Saved GP emulator: data/gp_exponential.joblib
Kernel: 10**2 * Matern(length_scale=[3.79, 10.2, 14.9, 40.1], nu=2.5) + WhiteKernel(noise_level=1e-08)

=== Step 3: Bayesian calibration (emcee) -> data/posterior_exponential.npy ===
Saved posterior samples to data/posterior_exponential.npy
exponential posterior mean: [-1.58609008e+01  4.69859815e-03] std: [0.10996537 0.00240217]

=== Step 4: UQ plots -> outputs/uq_exponential* ===

All done.
